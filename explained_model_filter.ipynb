{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from joblib import dump, load\n",
    "from pathlib import Path\n",
    "from aux_functions import read_data\n",
    "from CNN_Net import Net\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from pytorch_metric_learning import distances, losses, reducers, testers\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime('%Y-%m-%d')\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "EXP_NAME = 'v2-ensble'\n",
    "np.random.seed = SEED\n",
    "random.seed = SEED\n",
    "tf.random.set_seed(SEED)\n",
    "D1_DATA_DIR = Path('../data/patches-filter_by_area/d1/') # dataset 1\n",
    "D2_DATA_DIR = Path('../data/patches-filter_by_area/d2/') # dataset 2\n",
    "DATA_DIR = Path('./data/v1-and-fba/')\n",
    "MODEL_OUT_DIR = Path(f'models/{EXP_NAME}_{timestamp}')\n",
    "MODEL_OUT_DIR.mkdir(parents=True, exist_ok=False)\n",
    "TRAIN_SIZE = .7\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 10\n",
    "EMBEDDING_SIZE = 128\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = (96, 96)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados mistos: Dataset v1+v2\n",
    "v1 = \tmelhoria de contraste na imagem inteira **(7341 imagens)** \\\n",
    "v2 =\tmelhoria de constraste em áreas específicas da imagem **(4277 imagens)** \\\n",
    "data aug = \trotation_range=120, horizontal_flip=True, vertical_flip=True, zoom_range=0.3 **(10000 imagens)** \\\n",
    "**21390 exemplares da classe negativa**\n",
    "\n",
    "**TOTAL: 21618 'LEISH' x 21390 'NO-LEISH'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definir a função de perda com base na escolha de loss_select.\n",
    "- Inicializar o modelo de rede neural e o otimizador.\n",
    "- Realizar o treinamento do modelo com os dados de treino por um número especificado de épocas.\n",
    "- Gerar embeddings para os conjuntos de treino e teste.\n",
    "- Utilizar esses embeddings para treinar e testar um classificador SVM printando no final, os melhores hiperparams do classificador (C e gamma) e o número de dimensões do PCA.\n",
    "- Realizar a validação cruzada estratificada em vários splits para avaliar a estabilidade e confiabilidade do modelo.\n",
    "- Calcular e imprimir a média e o desvio padrão do recall para as duas classes.\n",
    "- Salvar o estado do modelo treinado para uso futuro, assim como o PCA e o Standard Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(loss_select, model):\n",
    "    '''\n",
    "    Salva o estado do modelo treinado em um arquivo.\n",
    "\n",
    "    @params\n",
    "    loss_select: Nome da função de perda utilizada durante o treinamento.\n",
    "    model: Modelo de rede neural a ser salvo.\n",
    "\n",
    "    @returns\n",
    "    None\n",
    "    '''\n",
    "    model_filename = MODEL_OUT_DIR.joinpath(f'model_{loss_select}_{EXP_NAME}_{timestamp}.pth')\n",
    "    torch.save(model.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, device, train_loader, optimizer, epoch):\n",
    "    '''\n",
    "    Treina o modelo fornecido com o conjunto de dados de treinamento.\n",
    "\n",
    "    @params\n",
    "    model: O modelo de rede neural a ser treinado.\n",
    "    loss_func: A função de perda a ser utilizada.\n",
    "    device: O dispositivo no qual o modelo está sendo treinado (CPU ou GPU).\n",
    "    train_loader: DataLoader contendo os dados de treinamento.\n",
    "    optimizer: O otimizador usado para ajuste dos parâmetros do modelo.\n",
    "    epoch: Número atual da época de treinamento.\n",
    "\n",
    "    @returns\n",
    "    Retorna a perda após a última iteração de treinamento na época atual.\n",
    "    '''\n",
    "    model.train()\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        loss = loss_func(embeddings, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                'Epoch {} Iteration {}: Loss = {}'.format(\n",
    "                    epoch, batch_idx, loss\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_all_embeddings(dataset, model):\n",
    "    '''\n",
    "    Gera embeddings para todos os exemplos em um conjunto de dados usando o modelo fornecido.\n",
    "\n",
    "    @params\n",
    "    dataset: O conjunto de dados para o qual os embeddings serão gerados.\n",
    "    model: Modelo de rede neural usado para gerar embeddings.\n",
    "\n",
    "    @returns\n",
    "    Retorna uma tupla contendo os embeddings e os rótulos correspondentes dos exemplos do conjunto de dados.\n",
    "    '''\n",
    "    tester = testers.BaseTester()\n",
    "    return tester.get_all_embeddings(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(loss_select, x_train_loader):\n",
    "    '''\n",
    "    Treina a CNN com base na função de perda especificada.\n",
    "\n",
    "    @params\n",
    "    loss_select: Uma string que especifica a função de perda a ser utilizada.\n",
    "    x_train_loader: DataLoader contendo os dados de treinamento.\n",
    "\n",
    "    @returns\n",
    "    Retorna o modelo treinado, o otimizador e uma lista contendo as perdas de treinamento para cada época.\n",
    "    '''\n",
    "    loss_func = None\n",
    "    if loss_select == 'Triplet':\n",
    "        distance = distances.CosineSimilarity()\n",
    "        reducer = reducers.ThresholdReducer(low=0)\n",
    "        loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "\n",
    "    if loss_select == 'NPairs':\n",
    "        loss_func = losses.NPairsLoss()\n",
    "\n",
    "    if loss_select == 'CosFace':\n",
    "        loss_func = losses.CircleLoss()\n",
    "\n",
    "    if loss_select == 'MultiSimilarity':\n",
    "        loss_func = losses.MultiSimilarityLoss(alpha = 2, beta = 50, base=0.5)\n",
    "\n",
    "    model = Net(EMBEDDING_SIZE, (1, *IMG_SIZE)).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    lss_train = []\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        lss = train(model, loss_func, device, x_train_loader, optimizer, epoch)\n",
    "        lss_train.append(lss)\n",
    "\n",
    "    return model, optimizer, lss_train\n",
    "\n",
    "def get_all_embeddings(dataset, model):\n",
    "    '''\n",
    "    Gera embeddings para todos os exemplos em um conjunto de dados usando o modelo fornecido.\n",
    "\n",
    "    @params\n",
    "    dataset: O conjunto de dados para o qual os embeddings serão gerados.\n",
    "    model: Modelo de rede neural usado para gerar embeddings.\n",
    "\n",
    "    @returns\n",
    "    Retorna uma tupla contendo os embeddings e os rótulos correspondentes dos exemplos do conjunto de dados.\n",
    "    '''\n",
    "    tester = testers.BaseTester()\n",
    "    return tester.get_all_embeddings(dataset, model)\n",
    "\n",
    "def train_eval_model(loss_select, train_set, test_set, model, C=None, gamma=None, perform_grid_search=False, to_save=False):\n",
    "    '''\n",
    "    Realiza Grid Search para hiperparâmetros do SVM se necessário, treina e avalia o modelo SVM.\n",
    "\n",
    "    @params\n",
    "    train_set: Conjunto de dados de treinamento.\n",
    "    test_set: Conjunto de dados de teste.\n",
    "    model: Modelo de rede neural para gerar embeddings.\n",
    "    C: Parâmetro de regularização para o modelo SVM. Se None, é determinado via Grid Search.\n",
    "    gamma: Parâmetro de kernel para o modelo SVM. Se None, é determinado via Grid Search.\n",
    "    perform_grid_search: Booleano para realizar ou não o Grid Search.\n",
    "    to_save: Booleano indicando se o modelo SVM e os pré-processadores devem ser salvos.\n",
    "\n",
    "    @returns\n",
    "    Retorna os rótulos verdadeiros de teste, as previsões feitas pelo modelo SVM, e os parâmetros C e gamma.\n",
    "    '''\n",
    "    print('Computing embeddings...')\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=0.9)\n",
    "    train_embeddings = pca.fit_transform(scaler.fit_transform(train_embeddings.cpu().numpy()))\n",
    "    test_embeddings = pca.transform(scaler.transform(test_embeddings.cpu().numpy()))\n",
    "\n",
    "    if perform_grid_search:\n",
    "        print('Performing GridSearch...')\n",
    "        clf = svm.SVC(kernel='rbf')\n",
    "        params = {'C': [1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001]}\n",
    "        search = GridSearchCV(clf, params, verbose=3, scoring='recall_macro', n_jobs=-1)\n",
    "        search.fit(train_embeddings, train_labels.cpu().numpy().ravel())\n",
    "        C, gamma = search.best_params_['C'], search.best_params_['gamma']\n",
    "        print(f'Best Params: C={C}, gamma={gamma}')\n",
    "        print(f'PCA dim ={pca.n_components_}')\n",
    "\n",
    "    clf = svm.SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "    clf.fit(train_embeddings, train_labels.cpu().numpy().ravel())\n",
    "    predictions = clf.predict(test_embeddings)\n",
    "    y_true_test = test_labels.cpu().numpy().ravel()\n",
    "    print(f'RESULTS FOR LOSS = [{loss_select}]')\n",
    "    print(classification_report(y_true_test, predictions))\n",
    "\n",
    "    if to_save:\n",
    "        dump(clf, MODEL_OUT_DIR.joinpath(f'clf_{loss_select}_{EXP_NAME}_{timestamp}.joblib'))\n",
    "        dump(scaler, MODEL_OUT_DIR.joinpath(f'scaler_{loss_select}_{EXP_NAME}_{timestamp}.joblib'))\n",
    "        dump(pca, MODEL_OUT_DIR.joinpath(f'pca_{loss_select}_{EXP_NAME}_{timestamp}.joblib'))\n",
    "        print('~ Joblib files saved.')\n",
    "\n",
    "    return y_true_test, predictions, C, gamma\n",
    "\n",
    "def cross_val_model(loss_select, train_set, model, best_C, best_gamma, n_folds=15):\n",
    "    '''\n",
    "    Realiza a validação cruzada estratificada do modelo SVM com os melhores hiperparâmetros encontrados.\n",
    "\n",
    "    @params\n",
    "    loss_select: Nome da função de perda utilizada durante o treinamento.\n",
    "    train_set: Conjunto de dados de treinamento. (torch.Dataset)\n",
    "    model: Modelo de rede neural.\n",
    "    best_C: Melhor valor de C encontrado para o SVM.\n",
    "    best_gamma: Melhor valor de gamma encontrado para o SVM.\n",
    "    n_folds: Número de folds para a validação cruzada.\n",
    "\n",
    "    @returns\n",
    "    None.\n",
    "    '''\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "    iteration = 1\n",
    "    recalls_fold_0 = []\n",
    "    recalls_fold_1 = []\n",
    "\n",
    "    for train_index, test_index in kf.split(train_set.indices, y_true_train):\n",
    "        print(f'-------> RUN {iteration}')\n",
    "        train_subset = torch.utils.data.Subset(train_set.dataset, train_index)\n",
    "        test_subset = torch.utils.data.Subset(train_set.dataset, test_index)\n",
    "\n",
    "        y_true_test, y_pred, *_ = train_eval_model(loss_select, train_subset, test_subset, model, C=best_C, gamma=best_gamma)\n",
    "\n",
    "        report = classification_report(y_true_test, y_pred, output_dict=True)\n",
    "        recalls_fold_0.append(report['0']['recall'])\n",
    "        recalls_fold_1.append(report['1']['recall'])\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    mean_recall_class_0 = np.mean(recalls_fold_0)\n",
    "    mean_recall_class_1 = np.mean(recalls_fold_1)\n",
    "    std_recall_class_0 = np.std(recalls_fold_0)\n",
    "    std_recall_class_1 = np.std(recalls_fold_1)\n",
    "\n",
    "    print(f'\\n Loss ===== {loss_select}')\n",
    "    print(f'Mean Recall (Class 0): {mean_recall_class_0}')\n",
    "    print(f'Mean Recall (Class 1): {mean_recall_class_1}')\n",
    "    print(f'Std Recall (Class 0): {std_recall_class_0}')\n",
    "    print(f'Std Recall (Class 1): {std_recall_class_1}')\n",
    "\n",
    "def save_model(loss_select, model):\n",
    "    model_filename = MODEL_OUT_DIR.joinpath(f'model_{loss_select}_{EXP_NAME}_{timestamp}.pth')\n",
    "    torch.save(model.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(loss_select, x_train, x_test, x_train_loader):\n",
    "    '''\n",
    "    Executa todo o pipeline de treinamento, avaliação e validação cruzada do modelo.\n",
    "\n",
    "    @params\n",
    "    loss_select: Nome da função de perda a ser utilizada. (string)\n",
    "    x_train: Conjunto de dados de treinamento. (torch.Dataset)\n",
    "    x_test: Conjunto de dados de teste. (torch.Dataset)\n",
    "    x_train_loader: DataLoader para o conjunto de treinamento. (torch.DataLoader)\n",
    "\n",
    "    @returns\n",
    "    None\n",
    "    '''\n",
    "    model, optim, losses_training = train_model(loss_select, x_train_loader)\n",
    "    *_, best_C, best_gamma = train_eval_model(loss_select, x_train, x_test, model, perform_grid_search=True, to_save=True)\n",
    "    cross_val_model(loss_select, x_train, model, best_C, best_gamma)\n",
    "    save_model(loss_select, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label format = {'leish': 0, 'no-leish': 1}\n",
      "train test split proportion = train[30105], test[12903]\n",
      "leish in training set = 15124\n",
      "leish in testing set = 6494\n",
      "Epoch 1 Iteration 0: Loss = 71.53922271728516\n",
      "Epoch 1 Iteration 100: Loss = 57.454227447509766\n",
      "Epoch 1 Iteration 200: Loss = 55.692989349365234\n",
      "Epoch 2 Iteration 0: Loss = 54.74848175048828\n",
      "Epoch 2 Iteration 100: Loss = 55.07919692993164\n",
      "Epoch 2 Iteration 200: Loss = 54.35858154296875\n",
      "Epoch 3 Iteration 0: Loss = 53.963783264160156\n",
      "Epoch 3 Iteration 100: Loss = 52.793792724609375\n",
      "Epoch 3 Iteration 200: Loss = 51.48012161254883\n",
      "Epoch 4 Iteration 0: Loss = 51.56048583984375\n",
      "Epoch 4 Iteration 100: Loss = 51.264259338378906\n",
      "Epoch 4 Iteration 200: Loss = 49.38299560546875\n",
      "Epoch 5 Iteration 0: Loss = 49.887168884277344\n",
      "Epoch 5 Iteration 100: Loss = 49.3829345703125\n",
      "Epoch 5 Iteration 200: Loss = 48.67662048339844\n",
      "Epoch 6 Iteration 0: Loss = 47.674869537353516\n",
      "Epoch 6 Iteration 100: Loss = 48.48349380493164\n",
      "Epoch 6 Iteration 200: Loss = 47.553367614746094\n",
      "Epoch 7 Iteration 0: Loss = 47.58183670043945\n",
      "Epoch 7 Iteration 100: Loss = 49.17539978027344\n",
      "Epoch 7 Iteration 200: Loss = 46.99030303955078\n",
      "Epoch 8 Iteration 0: Loss = 46.49927520751953\n",
      "Epoch 8 Iteration 100: Loss = 46.94034194946289\n",
      "Epoch 8 Iteration 200: Loss = 46.44721603393555\n",
      "Epoch 9 Iteration 0: Loss = 45.81028747558594\n",
      "Epoch 9 Iteration 100: Loss = 46.716522216796875\n",
      "Epoch 9 Iteration 200: Loss = 46.38671112060547\n",
      "Epoch 10 Iteration 0: Loss = 45.92321014404297\n",
      "Epoch 10 Iteration 100: Loss = 45.622650146484375\n",
      "Epoch 10 Iteration 200: Loss = 45.35260009765625\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 941/941 [00:21<00:00, 44.68it/s]\n",
      "100%|██████████| 404/404 [00:15<00:00, 26.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing GridSearch...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Params: C=10, gamma=0.01\n",
      "PCA dim =26\n",
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      6494\n",
      "           1       0.91      0.88      0.89      6409\n",
      "\n",
      "    accuracy                           0.90     12903\n",
      "   macro avg       0.90      0.90      0.90     12903\n",
      "weighted avg       0.90      0.90      0.90     12903\n",
      "\n",
      "~ Joblib files saved.\n",
      "-------> RUN 1\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:44<00:00, 19.81it/s]\n",
      "100%|██████████| 63/63 [00:10<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1450\n",
      "           1       0.84      0.77      0.80       557\n",
      "\n",
      "    accuracy                           0.90      2007\n",
      "   macro avg       0.88      0.86      0.87      2007\n",
      "weighted avg       0.89      0.90      0.89      2007\n",
      "\n",
      "-------> RUN 2\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 46.09it/s]\n",
      "100%|██████████| 63/63 [00:07<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1449\n",
      "           1       0.88      0.78      0.83       558\n",
      "\n",
      "    accuracy                           0.91      2007\n",
      "   macro avg       0.90      0.87      0.88      2007\n",
      "weighted avg       0.91      0.91      0.91      2007\n",
      "\n",
      "-------> RUN 3\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 45.54it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      1420\n",
      "           1       0.86      0.77      0.81       587\n",
      "\n",
      "    accuracy                           0.90      2007\n",
      "   macro avg       0.88      0.86      0.87      2007\n",
      "weighted avg       0.89      0.90      0.89      2007\n",
      "\n",
      "-------> RUN 4\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 44.82it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      1444\n",
      "           1       0.83      0.75      0.79       563\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.87      0.84      0.85      2007\n",
      "weighted avg       0.88      0.89      0.88      2007\n",
      "\n",
      "-------> RUN 5\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 45.15it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      1437\n",
      "           1       0.85      0.75      0.80       570\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.88      0.85      0.86      2007\n",
      "weighted avg       0.89      0.89      0.89      2007\n",
      "\n",
      "-------> RUN 6\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 45.10it/s]\n",
      "100%|██████████| 63/63 [00:07<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1457\n",
      "           1       0.83      0.77      0.80       550\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.87      0.86      0.86      2007\n",
      "weighted avg       0.89      0.89      0.89      2007\n",
      "\n",
      "-------> RUN 7\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 44.63it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      1406\n",
      "           1       0.85      0.76      0.80       601\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.88      0.85      0.86      2007\n",
      "weighted avg       0.89      0.89      0.89      2007\n",
      "\n",
      "-------> RUN 8\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 45.02it/s]\n",
      "100%|██████████| 63/63 [00:07<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1458\n",
      "           1       0.82      0.76      0.79       549\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.87      0.85      0.86      2007\n",
      "weighted avg       0.89      0.89      0.89      2007\n",
      "\n",
      "-------> RUN 9\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 45.23it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1434\n",
      "           1       0.85      0.75      0.79       573\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.88      0.85      0.86      2007\n",
      "weighted avg       0.89      0.89      0.89      2007\n",
      "\n",
      "-------> RUN 10\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 45.56it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      1429\n",
      "           1       0.86      0.78      0.82       578\n",
      "\n",
      "    accuracy                           0.90      2007\n",
      "   macro avg       0.89      0.87      0.88      2007\n",
      "weighted avg       0.90      0.90      0.90      2007\n",
      "\n",
      "-------> RUN 11\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 44.51it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      1437\n",
      "           1       0.86      0.76      0.81       570\n",
      "\n",
      "    accuracy                           0.90      2007\n",
      "   macro avg       0.89      0.86      0.87      2007\n",
      "weighted avg       0.90      0.90      0.90      2007\n",
      "\n",
      "-------> RUN 12\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 44.46it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1465\n",
      "           1       0.83      0.76      0.79       542\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.87      0.85      0.86      2007\n",
      "weighted avg       0.89      0.89      0.89      2007\n",
      "\n",
      "-------> RUN 13\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:18<00:00, 46.31it/s]\n",
      "100%|██████████| 63/63 [00:07<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93      1450\n",
      "           1       0.85      0.75      0.79       557\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.88      0.85      0.86      2007\n",
      "weighted avg       0.89      0.89      0.89      2007\n",
      "\n",
      "-------> RUN 14\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 45.32it/s]\n",
      "100%|██████████| 63/63 [00:08<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1427\n",
      "           1       0.85      0.73      0.79       580\n",
      "\n",
      "    accuracy                           0.89      2007\n",
      "   macro avg       0.87      0.84      0.86      2007\n",
      "weighted avg       0.88      0.89      0.88      2007\n",
      "\n",
      "-------> RUN 15\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 879/879 [00:19<00:00, 45.54it/s]\n",
      "100%|██████████| 63/63 [00:07<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LOSS = [CosFace]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93      1455\n",
      "           1       0.85      0.77      0.81       552\n",
      "\n",
      "    accuracy                           0.90      2007\n",
      "   macro avg       0.88      0.86      0.87      2007\n",
      "weighted avg       0.90      0.90      0.90      2007\n",
      "\n",
      "\n",
      " Loss ===== CosFace\n",
      "Mean Recall (Class 0): 0.9464393471322047\n",
      "Mean Recall (Class 1): 0.761307872865164\n",
      "Std Recall (Class 0): 0.005418160385782211\n",
      "Std Recall (Class 1): 0.012872774179429749\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, x_train_loader, x_test_loader, y_true_train, y_true_test = read_data(DATA_DIR, BATCH_SIZE, TRAIN_SIZE)\n",
    "loss = ['Triplet', 'NPairs', 'CosFace', 'MultiSimilarity']\n",
    "run_full_pipeline(loss[2], x_train, x_test, x_train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
