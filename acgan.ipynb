{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repurposing Hao L, Shen P, Pan Z and Xu Y (2023) ACGAN algorithm for synthetic data generation for few-shot classification\n",
    "The main contributions of this paper (doi: 10.3389/fphy.2023.1208781) are as follows:\n",
    "\n",
    "• The residual module is introduced into the network structure of adversarial learning to contribute to the feature extraction. Moreover, multiple convolutional layers are employed in the model architecture to replace the original classification layer, further boosting the classification performance of the model.\n",
    "\n",
    "• A multi-level semantic feature extractor (MSFE) which effectively extracts features at different levels is designed, fully capturing diverse semantic information of images to guide the generator in sample generation and improve the quality of generated samples.\n",
    "\n",
    "• The proposed method can generate high-quality samples to compensate for the deficiencies under few-shot conditions, further improving the classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Gerador\n",
    "- Camada totalmente conectada para mapear o vetor z e o rótulo c para uma dimensão que possa ser redimensionada para uma forma que funcione como entrada para as convoluções transpostas.\n",
    "- Operações de upsampling antes das duas primeiras camadas convolucionais.\n",
    "- Camadas convolucionais transpostas para aumentar gradativamente a resolução da imagem gerada.\n",
    "- Módulos residuais inseridos entre as camadas convolucionais.\n",
    "- Normalização em lote e Leaky-ReLU após cada convolução.\n",
    "- Camada de saída para produzir a imagem com a resolução desejada (96x96x3 neste caso).\n",
    "\n",
    "> Discriminador\n",
    "- Camadas convolucionais para extrair características das imagens de entrada.\n",
    "- Módulos residuais após a primeira camada convolucional.\n",
    "- Dropout após as convoluções para prevenir sobreajuste.\n",
    "- Leaky-ReLU após cada convolução.\n",
    "- Uma camada final para classificar as imagens como reais ou falsas, e possivelmente outra camada para a classificação auxiliar (contendo ou não parasitas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_Net import Net as CustomNet\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "CUDA_LAUNCH_BLOCKING = \"1\"\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (96, 96)\n",
    "CHANNELS = 1\n",
    "Z_DIM = 128  # dimensão do espaço latente\n",
    "NUM_CLASSES = C_DIM = 2   # dimensão do vetor de condição (rótulos)\n",
    "NUM_EPOCHS = 10000\n",
    "LEARNING_RATE = 0.0002\n",
    "B1, B2 = 0.5, 0.999\n",
    "BATCH_SIZE = 64\n",
    "N_CRITIC = 5 # num vezes discriminator é treinado por iteração do generator\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EXP_NAME = 'v1-acgan'\n",
    "now = datetime.datetime.now()\n",
    "TIMESTAMP = now.strftime(\"%Y-%m-%d\")\n",
    "MODEL_OUT_DIR = Path(f'models/{EXP_NAME}_{TIMESTAMP}')\n",
    "# MODEL_OUT_DIR.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "IMAGE_PATH = Path('../data/all-patches/') # 2139 leish | 2803 no-leish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extractor from previous researches (CNN tri-set with different losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomFeatureExtractor(nn.Module):\n",
    "#     '''\n",
    "#     Use previously trained CNN feature extractor\n",
    "#     '''\n",
    "#     def __init__(self, pretrained_model_path):\n",
    "#         super(CustomFeatureExtractor, self).__init__()\n",
    "#         self.pretrained_model = CustomNet(Z_DIM, (1, *IMG_SIZE)).to(DEVICE)\n",
    "#         self.pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "#         for param in self.pretrained_model.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "#         self.pretrained_model.fc1 = nn.Identity() # remove a fc e a operação de achatamento\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # passa x apenas pelas convlayers e de pooling\n",
    "#         x = self.pretrained_model.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.pretrained_model.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.pretrained_model.dropout1(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class for residual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GeneratorResidualBlock(nn.Module):\n",
    "#     def __init__(self, channels, feature_extractor):\n",
    "#         super(GeneratorResidualBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(channels)\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "#         self.feature_extractor = feature_extractor\n",
    "#         self.feature_extractor.eval()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         with torch.no_grad():\n",
    "#             extracted_features = self.feature_extractor(x)\n",
    "\n",
    "#         residual = x\n",
    "#         out = self.leaky_relu(self.bn1(self.conv1(x)))\n",
    "#         out = self.bn2(self.conv2(out))\n",
    "#         out += residual + extracted_features\n",
    "#         out = self.leaky_relu(out)\n",
    "#         return out\n",
    "\n",
    "class DiscriminatorResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DiscriminatorResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = self.leaky_relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class for generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, c_dim, img_size, channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = channels\n",
    "\n",
    "        self.fc = nn.Linear(z_dim + c_dim, 128 * (self.img_size[0] // 4) * (self.img_size[1] // 4))\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv1 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            DiscriminatorResidualBlock(64),\n",
    "            DiscriminatorResidualBlock(64),\n",
    "            DiscriminatorResidualBlock(64)\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z, c):\n",
    "        y_one_hot = torch.nn.functional.one_hot(c, num_classes=2).float()  # [batch_size, c_dim]\n",
    "        y_one_hot = y_one_hot.view(64, 2, 1, 1)\n",
    "        x = torch.cat([z, y_one_hot], 1)\n",
    "        x = x.view(64, -1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 128, self.img_size[0]//4, self.img_size[1]//4)\n",
    "        x = self.upsample(x)\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = self.upsample(x)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.tanh(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels, num_classes):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(channels, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            DiscriminatorResidualBlock(64),\n",
    "            DiscriminatorResidualBlock(64),\n",
    "            DiscriminatorResidualBlock(64)\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv6 = nn.Conv2d(1024, 2048, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc_real_fake = nn.Linear(2048 * 2 * 2, 1)\n",
    "        self.fc_clf = nn.Linear(2048 * 2 * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.leaky_relu(self.conv1(x)))\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.dropout(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.dropout(F.leaky_relu(self.conv3(x)))\n",
    "        x = self.dropout(F.leaky_relu(self.conv4(x)))\n",
    "        x = self.dropout(F.leaky_relu(self.conv5(x)))\n",
    "        x = self.dropout(F.leaky_relu(self.conv6(x)))\n",
    "        x = x.view(-1, 2048 * 2 * 2)\n",
    "        real_fake_logits = self.fc_real_fake(x)\n",
    "        clf_logits = self.fc_clf(x)\n",
    "\n",
    "        return real_fake_logits, clf_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n",
    "    '''\n",
    "    Calcula a penalidade de gradiente para o termo de regularização. Garante que os gradientes não cresçam\n",
    "    demais.\n",
    "    '''\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=real_samples.device)\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates, _ = discriminator(interpolates)\n",
    "    fake = torch.ones(d_interpolates.size(), device=real_samples.device, requires_grad=False)\n",
    "\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "\n",
    "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean() # norma L2 dos gradientes\n",
    "\n",
    "def discriminator_loss(real_images, fake_images, real_labels, discriminator, gp_weight=10):\n",
    "    real_validity, real_class_logits = discriminator(real_images)\n",
    "    fake_validity, _ = discriminator(fake_images.detach())\n",
    "\n",
    "    # Wasserstein = diferença entre as médias das saídas para imagens reais e falsas\n",
    "    wasserstein_loss = fake_validity.mean() - real_validity.mean()\n",
    "    gradient_penalty = compute_gradient_penalty(discriminator, real_images.data, fake_images.data)\n",
    "    clf_loss = F.cross_entropy(real_class_logits, real_labels)\n",
    "\n",
    "    return wasserstein_loss + gp_weight * gradient_penalty + clf_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(discriminator, fake_images, labels, criterion):\n",
    "    validity, predicted_labels = discriminator(fake_images)\n",
    "    ls_loss = -torch.mean(validity) # negando para incentivar a maximizar o erro do discrim.\n",
    "    labels = labels.unsqueeze(1)\n",
    "    lc_loss = criterion(predicted_labels, labels.float()) # cross entropy loss\n",
    "\n",
    "    return lc_loss + ls_loss # L(G) = L_c - (- L_s(G)) fórmula 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading and class instanciation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((96,96)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(root=IMAGE_PATH, transform=transform)\n",
    "\n",
    "    train_size = int(2/3 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    leish_train = sum(label == 0 for _, label in train_dataset)\n",
    "    leish_test = sum(label == 0 for _, label in test_dataset)\n",
    "\n",
    "    print(f'label format = {dataset.class_to_idx}')\n",
    "    print(f'train test split proportion = train[{len(train_dataset)}], test[{len(test_dataset)}]')\n",
    "    print(f'leish in training set = {leish_train}')\n",
    "    print(f'leish in testing set = {leish_test}')\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label format = {'leish': 0, 'no-leish': 1}\n",
      "train test split proportion = train[3294], test[1648]\n",
      "leish in training set = 1444\n",
      "leish in testing set = 695\n"
     ]
    }
   ],
   "source": [
    "# triplet = CustomFeatureExtractor(\n",
    "#     pretrained_model_path='./models/v1-ensble_2023-11-07\\model_Triplet_v1-ensble_2023-11-07.pth'\n",
    "# )\n",
    "# cosface = CustomFeatureExtractor(\n",
    "#     pretrained_model_path='./models/v1-ensble_2023-11-07\\model_CosFace_v1-ensble_2023-11-07.pth'\n",
    "# )\n",
    "# multisim = CustomFeatureExtractor(\n",
    "#     pretrained_model_path='./models/v1-ensble_2023-11-07\\model_MultiSimilarity_v1-ensble_2023-11-07.pth'\n",
    "# )\n",
    "\n",
    "# feature_extractors = nn.ModuleList([triplet, cosface, multisim])\n",
    "generator = Generator(Z_DIM, C_DIM, IMG_SIZE, CHANNELS).to(DEVICE)\n",
    "discriminator = Discriminator(CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "GEN_OPTIM = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(B1, B2))\n",
    "DISC_OPTIM = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(B1, B2))\n",
    "CRITERION = torch.nn.BCELoss()\n",
    "\n",
    "train_loader, test_loader = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train function\n",
    "<ul>\n",
    "    <li>Iterar sobre as épocas.</li>\n",
    "    <li>Dentro de cada época, iterar sobre os dados no DataLoader.</li>\n",
    "    <li>Gerar amostras de ruído, labels, e produzir imagens falsas com o gerador.</li>\n",
    "    <li>Alimentar imagens reais e falsas no discriminador para obter os scores.</li>\n",
    "    <li>Calcular a perda do discriminador, incluindo a Wasserstein loss, a penalidade de gradiente e a perda de classificação.</li>\n",
    "    <li>Atualizar os parâmetros do discriminador.</li>\n",
    "    <li>Calcular a perda do gerador e atualizar seus parâmetros.</li>\n",
    "    <li>Registrar as perdas para acompanhamento e salvar as imagens geradas periodicamente.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        generator,\n",
    "        discriminator,\n",
    "        data_loader,\n",
    "        gen_optim=GEN_OPTIM,\n",
    "        disc_optim=DISC_OPTIM,\n",
    "        criterion=CRITERION,\n",
    "        z_dim=Z_DIM,\n",
    "        c_dim=C_DIM,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        device=DEVICE,\n",
    "        save_image_interval=1000):\n",
    "    gen_losses, disc_losses = [], []\n",
    "    size_dl = len(data_loader)\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc='EPOCHS'):\n",
    "        for i, (real_images, labels) in enumerate(data_loader):\n",
    "            real_images, labels = real_images.to(device), labels.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "            fake_labels = torch.randint(0, c_dim, (batch_size,), device=device)\n",
    "\n",
    "            fake_images = generator(z, fake_labels)\n",
    "\n",
    "            disc_optim.zero_grad()\n",
    "            d_loss = discriminator_loss(real_images, fake_images, labels, discriminator)\n",
    "            d_loss.backward()\n",
    "            disc_optim.step()\n",
    "            disc_losses.append(d_loss.item())\n",
    "\n",
    "            gen_optim.zero_grad()\n",
    "            g_loss = generator_loss(discriminator, fake_images, fake_labels, criterion)\n",
    "            g_loss.backward()\n",
    "            gen_optim.step()\n",
    "            gen_losses.append(g_loss.item())\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}] : Step [{i+1}/{size_dl}] '\n",
    "                      f'>> discriminator loss = {d_loss.item()}'\n",
    "                      f'| generator loss = {g_loss.item()}')\n",
    "\n",
    "            if epoch % save_image_interval==0 and i == size_dl-1:\n",
    "                with torch.no_grad():\n",
    "                    generator.eval()\n",
    "                    test_z = torch.randn(5, z_dim, 1, 1, device=device)\n",
    "                    test_labels = torch.randint(0, c_dim, (5,), device=device)\n",
    "                    test_images = generator(test_z, test_labels)\n",
    "                    test_pred_labels = discriminator(test_images)[1]\n",
    "                    generator.train()\n",
    "\n",
    "                    for j, image in enumerate(test_images):\n",
    "                        predicted_classes = torch.argmax(test_pred_labels, dim=1)\n",
    "                        save_image(image, f'./generated_images/label_{predicted_classes}_epoch_{epoch}_image_{j}.png', normalize=True)\n",
    "\n",
    "    torch.save(generator.state_dict(), MODEL_OUT_DIR.joinpath(f'generator_{EXP_NAME}_{TIMESTAMP}.pth'))\n",
    "    torch.save(discriminator.state_dict(), MODEL_OUT_DIR.joinpath(f'discriminator_{EXP_NAME}_{TIMESTAMP}.pth'))\n",
    "\n",
    "    return gen_losses, disc_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCHS:   0%|          | 0/10000 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ynk9a\\OneDrive\\Documentos\\TCC\\Leishmania\\semana1\\acgan.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/acgan.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gen_losses, disc_losses \u001b[39m=\u001b[39m train(generator, discriminator, train_loader)\n",
      "\u001b[1;32mc:\\Users\\ynk9a\\OneDrive\\Documentos\\TCC\\Leishmania\\semana1\\acgan.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/acgan.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m disc_optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/acgan.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m d_loss \u001b[39m=\u001b[39m discriminator_loss(real_images, fake_images, labels, discriminator)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/acgan.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m d_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/acgan.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m disc_optim\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/acgan.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m disc_losses\u001b[39m.\u001b[39mappend(d_loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "gen_losses, disc_losses = train(generator, discriminator, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated image quality: visual evaluation, analize generated_images folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acgan(discriminator, dataloader, device):\n",
    "    discriminator.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, class_logits = discriminator(images)\n",
    "            preds = torch.argmax(class_logits, dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # accuracy = accuracy_score(all_labels, all_preds)\n",
    "    # precision = precision_score(all_labels, all_preds)\n",
    "    # recall = recall_score(all_labels, all_preds)\n",
    "    # f1 = f1_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    class_report = classification_report(all_labels, all_preds, target_names=['Leish', 'No-leish'])\n",
    "\n",
    "    # print(f\"Acurácia: {accuracy}\")\n",
    "    # print(f\"Precisão: {precision}\")\n",
    "    # print(f\"Recall: {recall}\")\n",
    "    # print(f\"F1-Score: {f1}\")\n",
    "    print(class_report)\n",
    "\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "    plt.xlabel('Predições')\n",
    "    plt.ylabel('Verdadeiros')\n",
    "    plt.show()\n",
    "\n",
    "    discriminator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_acgan(discriminator, dataloader, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
