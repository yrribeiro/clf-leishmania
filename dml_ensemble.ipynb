{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from joblib import dump, load\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from scipy.stats import mode\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from pytorch_metric_learning import distances, losses, reducers, testers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "EXP_NAME = 'v1-ensble'\n",
    "np.random.seed = SEED\n",
    "random.seed = SEED\n",
    "tf.random.set_seed(SEED)\n",
    "DATA_DIR = Path('../data/all-patches/')\n",
    "MODEL_OUT_DIR = Path(f'models/{EXP_NAME}_{timestamp}')\n",
    "# MODEL_OUT_DIR.mkdir(parents=True, exist_ok=False)\n",
    "TRAIN_SIZE = .7\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 10\n",
    "EMBEDDING_SIZE = 128\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = (1, 96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing complete white patches generated for negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_leish_pt = DATA_DIR.joinpath('no-leish')\n",
    "\n",
    "# count_rm_img, count_imgs = 0, 0\n",
    "# for path in no_leish_pt.glob('*.png'):\n",
    "#     count_imgs += 1\n",
    "#     with Image.open(path) as img:\n",
    "#         img = np.asarray(img)\n",
    "#         size = reduce((lambda x,y: x*y), img.shape)\n",
    "#         if np.count_nonzero(img == 255) > 0.5 * size:\n",
    "#             os.remove(path)\n",
    "#             # print(f'{path} removed')\n",
    "#             count_rm_img+=1\n",
    "# print(f'Removed {count_rm_img}. Total = {count_imgs-count_rm_img}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive class. Current proportion: 197 - 2803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#     rotation_range=120,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "#     zoom_range=0.3,\n",
    "#     preprocessing_function=lambda x: x/255\n",
    "# )\n",
    "\n",
    "# def generate_data(input_imgs, out_folder):\n",
    "#     for i in input_imgs:\n",
    "#         image = np.expand_dims(plt.imread(i), 0)\n",
    "#         datagen.fit(image)\n",
    "#         # './semana18/all_patches_splitted/val/leish/'\n",
    "#         for x, val in zip(datagen.flow(image,\n",
    "#             save_to_dir=out_folder,\n",
    "#             save_prefix='aug_',\n",
    "#             save_format='png'),range(10)):\n",
    "            # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leish_pt = DATA_DIR.joinpath('leish').glob('*.png')\n",
    "# out_aug_leish_pt = DATA_DIR.joinpath('aug') # visualize image quality before merging with real images\n",
    "\n",
    "# out_aug_leish_pt.mkdir(parents=True, exist_ok=False)\n",
    "# generate_data(leish_pt, out_aug_leish_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proporção final: 2139 - 2803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 4942\n",
       "    Root location: ..\\data\\all-patches\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Grayscale(num_output_channels=1)\n",
       "               Resize(size=(96, 96), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.Grayscale(num_output_channels=1),\n",
    "#     transforms.Resize((96, 96)),\n",
    "#     transforms.ToTensor(),  # converte a imagem para torch.Tensor e normaliza [0.0,1.0]\n",
    "# ])\n",
    "# dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(TRAIN_SIZE * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((96, 96)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "    train_size = int(TRAIN_SIZE * len(dataset))\n",
    "    # test_size = len(dataset) - train_size\n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    train_indices, test_indices = indices[:train_size], indices[train_size:]\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Obtendo as etiquetas verdadeiras do test_dataset usando Subset\n",
    "    train_true_labels = [dataset.targets[idx] for idx in train_indices]\n",
    "    test_true_labels = [dataset.targets[idx] for idx in test_indices]\n",
    "\n",
    "    leish_train = sum(label == 0 for _, label in train_dataset)\n",
    "    leish_test = sum(label == 0 for _, label in test_dataset)\n",
    "\n",
    "    print(f'label format = {dataset.class_to_idx}')\n",
    "    print(f'train test split proportion = train[{len(train_dataset)}], test[{len(test_dataset)}]')\n",
    "    print(f'leish in training set = {leish_train}')\n",
    "    print(f'leish in testing set = {leish_test}')\n",
    "\n",
    "    return train_dataset, test_dataset, train_loader, test_loader, train_true_labels, test_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label format = {'leish': 0, 'no-leish': 1}\n",
      "train test split proportion = train[3459], test[1483]\n",
      "leish in training set = 1484\n",
      "leish in testing set = 655\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, train_loader, test_loader, train_true_labels, test_true_labels = read_data(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label format = {'leish': 0, 'no-leish': 1}\n",
      "train test split proportion = train[3459], test[1483]\n",
      "leish in training set = 1523\n",
      "leish in testing set = 616\n"
     ]
    }
   ],
   "source": [
    "# leish_train = sum(label == 0 for _, label in train_dataset)\n",
    "# leish_test = sum(label == 0 for _, label in test_dataset)\n",
    "\n",
    "# print(f'label format = {dataset.class_to_idx}')\n",
    "# print(f'train test split proportion = train[{len(train_dataset)}], test[{len(test_dataset)}]')\n",
    "# print(f'leish in training set = {leish_train}')\n",
    "# print(f'leish in testing set = {leish_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc_input_size = self.calculate_fc_input_size(IMG_SIZE)\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "    def calculate_fc_input_size(self, input_size):\n",
    "        x = torch.randn(1, *input_size)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        loss = loss_func(embeddings, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch {} Iteration {}: Loss = {}\".format(\n",
    "                    epoch, batch_idx, loss\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_all_embeddings(dataset, model):\n",
    "    tester = testers.BaseTester()\n",
    "    return tester.get_all_embeddings(dataset, model)\n",
    "\n",
    "def test(train_set, test_set, model):\n",
    "    '''Pegar os melhores hiperparametros do classificador'''\n",
    "    print('Embedding Train')\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    print('Embedding Test')\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "    train_labels = train_labels.squeeze(1)\n",
    "    test_labels = test_labels.squeeze(1)\n",
    "    print(\"Computing KNN\")\n",
    "    '''\n",
    "    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    clf.fit(train_embeddings.cpu().numpy(), train_labels.cpu().numpy())\n",
    "    #pickle.dump(neigh, open('knn_Dataset2Aug+Dataset2Real_multisimilarity_2103.sav', 'wb'))'''\n",
    "\n",
    "    clf = svm.SVC(kernel = 'rbf', C = 1000, gamma = 1)\n",
    "    #clf.fit(train_embeddings.cpu().numpy(), train_labels.cpu().numpy())\n",
    "    # defining parameter range\n",
    "    params = {\n",
    "        'C': [10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "        }\n",
    "    #xgb = XGBClassifier()\n",
    "    #search = RandomizedSearchCV(xgb, param_distributions=params,n_iter=5, scoring='recall_macro', n_jobs=4, verbose=3)\n",
    "    search = GridSearchCV(clf, params, verbose=3, scoring='recall_macro')\n",
    "\n",
    "    #PCA\n",
    "    ss = StandardScaler()\n",
    "    x_scaled = ss.fit_transform(train_embeddings.cpu())\n",
    "    x_test_scaled = ss.transform(test_embeddings.cpu())\n",
    "\n",
    "    pca = PCA()\n",
    "    Xt = pca.fit_transform(x_scaled)\n",
    "    Xtest = pca.transform(x_test_scaled)\n",
    "\n",
    "    p = 0\n",
    "    t = 0\n",
    "    for pca in pca.explained_variance_ratio_:\n",
    "        if t < 90:\n",
    "            p += 1\n",
    "            t += pca * 100\n",
    "\n",
    "    print(f'dimensoes pca: {p}')\n",
    "    x_train = Xt[:,:p]\n",
    "    x_test = Xtest[:,:p]\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    search.fit(x_train, train_labels.cpu().numpy())\n",
    "    print(search.best_params_)\n",
    "    predicts = search.predict(x_test)\n",
    "\n",
    "    return test_embeddings, test_labels, predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 2.331930637359619\n",
      "Epoch 2 Iteration 0: Loss = 2.1792194843292236\n",
      "Epoch 3 Iteration 0: Loss = 2.1913743019104004\n",
      "Epoch 4 Iteration 0: Loss = 2.1849164962768555\n",
      "Epoch 5 Iteration 0: Loss = 2.1862926483154297\n",
      "Epoch 6 Iteration 0: Loss = 2.1997342109680176\n",
      "Epoch 7 Iteration 0: Loss = 2.1896414756774902\n",
      "Epoch 8 Iteration 0: Loss = 2.1848902702331543\n",
      "Epoch 9 Iteration 0: Loss = 2.1934726238250732\n",
      "Epoch 10 Iteration 0: Loss = 2.1812148094177246\n"
     ]
    }
   ],
   "source": [
    "loss = ['Triplet', 'NPairs', 'CosFace', 'MultiSimilarity']\n",
    "loss_select = loss[3]\n",
    "\n",
    "if loss_select == 'Triplet':\n",
    "  distance = distances.CosineSimilarity()\n",
    "  reducer = reducers.ThresholdReducer(low=0)\n",
    "  loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "\n",
    "if loss_select == 'NPairs':\n",
    "  loss_func = losses.NPairsLoss()\n",
    "\n",
    "if loss_select == 'CosFace':\n",
    "  loss_func = losses.CircleLoss()\n",
    "\n",
    "if loss_select == 'MultiSimilarity':\n",
    "  loss_func = losses.MultiSimilarityLoss(alpha = 2, beta = 50, base=0.5)\n",
    "\n",
    "# train_loader\n",
    "# test_loader\n",
    "\n",
    "model = Net(EMBEDDING_SIZE).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "  lss = train(model, loss_func, device, train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/109 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ynk9a\\OneDrive\\Documentos\\TCC\\Leishmania\\semana1\\cnn.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_embeddings_real, test_labels_real, y_pred_train, y_pred_test \u001b[39m=\u001b[39m test(train_dataset, test_dataset, model)\n",
      "\u001b[1;32mc:\\Users\\ynk9a\\OneDrive\\Documentos\\TCC\\Leishmania\\semana1\\cnn.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(train_set, test_set, model):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEmbedding Train\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     train_embeddings, train_labels \u001b[39m=\u001b[39m get_all_embeddings(train_set, model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEmbedding Test\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     test_embeddings, test_labels \u001b[39m=\u001b[39m get_all_embeddings(test_set, model)\n",
      "\u001b[1;32mc:\\Users\\ynk9a\\OneDrive\\Documentos\\TCC\\Leishmania\\semana1\\cnn.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_all_embeddings\u001b[39m(dataset, model):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     tester \u001b[39m=\u001b[39m testers\u001b[39m.\u001b[39mBaseTester()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ynk9a/OneDrive/Documentos/TCC/Leishmania/semana1/cnn.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tester\u001b[39m.\u001b[39;49mget_all_embeddings(dataset, model)\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\pytorch_metric_learning\\testers\\base_tester.py:119\u001b[0m, in \u001b[0;36mBaseTester.get_all_embeddings\u001b[1;34m(self, dataset, trunk_model, embedder_model, collate_fn, eval, return_as_numpy)\u001b[0m\n\u001b[0;32m    115\u001b[0m     embedder_model\u001b[39m.\u001b[39meval()\n\u001b[0;32m    116\u001b[0m dataloader \u001b[39m=\u001b[39m c_f\u001b[39m.\u001b[39mget_eval_dataloader(\n\u001b[0;32m    117\u001b[0m     dataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader_num_workers, collate_fn\n\u001b[0;32m    118\u001b[0m )\n\u001b[1;32m--> 119\u001b[0m embeddings, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_all_embeddings(\n\u001b[0;32m    120\u001b[0m     dataloader, trunk_model, embedder_model\n\u001b[0;32m    121\u001b[0m )\n\u001b[0;32m    122\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaybe_normalize(embeddings)\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m return_as_numpy:\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\pytorch_metric_learning\\testers\\base_tester.py:77\u001b[0m, in \u001b[0;36mBaseTester.compute_all_embeddings\u001b[1;34m(self, dataloader, trunk_model, embedder_model)\u001b[0m\n\u001b[0;32m     75\u001b[0m s, e \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm\u001b[39m.\u001b[39mtqdm(dataloader)):\n\u001b[0;32m     78\u001b[0m         img, label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_and_label_getter(data)\n\u001b[0;32m     79\u001b[0m         label \u001b[39m=\u001b[39m c_f\u001b[39m.\u001b[39mprocess_label(label, \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_mapper)\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_embeddings_real, test_labels_real, y_pred = test(train_dataset, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:08<00:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS ========  MultiSimilarity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.66       616\n",
      "           1       0.79      0.62      0.70       867\n",
      "\n",
      "    accuracy                           0.68      1483\n",
      "   macro avg       0.69      0.69      0.68      1483\n",
      "weighted avg       0.70      0.68      0.68      1483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tester = testers.BaseTester()\n",
    "test_embeddings, test_labels =  tester.get_all_embeddings(test_dataset, model)\n",
    "y_test_int = test_labels.squeeze(1).cpu()\n",
    "print('LOSS ======== ', loss_select)\n",
    "print(classification_report(y_test_int, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_set, test_set, model, C, gamma, to_save=False):\n",
    "    print('Computing embeddings...')\n",
    "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
    "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
    "\n",
    "    train_labels = train_labels.cpu().numpy().ravel()\n",
    "    test_labels = test_labels.cpu().numpy().ravel()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_embeddings = scaler.fit_transform(train_embeddings.cpu().numpy())\n",
    "    test_embeddings = scaler.transform(test_embeddings.cpu().numpy())\n",
    "\n",
    "    pca = PCA(n_components=0.9)\n",
    "    train_embeddings = pca.fit_transform(train_embeddings)\n",
    "    test_embeddings = pca.transform(test_embeddings)\n",
    "\n",
    "    clf = svm.SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "    clf.fit(train_embeddings, train_labels)\n",
    "\n",
    "    predictions = clf.predict(test_embeddings)\n",
    "\n",
    "    if to_save:# Salvar o classificador e os pré-processadores\n",
    "        dump(clf, MODEL_OUT_DIR.joinpath(f'clf_{loss_select}_{EXP_NAME}_{timestamp}.joblib'))\n",
    "        dump(scaler, MODEL_OUT_DIR.joinpath(f'scaler_{loss_select}_{EXP_NAME}_{timestamp}.joblib'))\n",
    "        dump(pca, MODEL_OUT_DIR.joinpath(f'pca_{loss_select}_{EXP_NAME}_{timestamp}.joblib'))\n",
    "\n",
    "    return test_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 0\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:13<00:00,  7.90it/s]\n",
      "100%|██████████| 47/47 [00:08<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 1\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:14<00:00,  7.64it/s]\n",
      "100%|██████████| 47/47 [00:08<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 2\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:14<00:00,  7.41it/s]\n",
      "100%|██████████| 47/47 [00:08<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 3\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:14<00:00,  7.48it/s]\n",
      "100%|██████████| 47/47 [00:08<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 4\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:14<00:00,  7.44it/s]\n",
      "100%|██████████| 47/47 [00:08<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 5\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:14<00:00,  7.55it/s]\n",
      "100%|██████████| 47/47 [00:08<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 6\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:14<00:00,  7.32it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 7\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:15<00:00,  7.10it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 8\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:15<00:00,  7.13it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 9\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:15<00:00,  7.13it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 10\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:15<00:00,  7.09it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 11\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:16<00:00,  6.51it/s]\n",
      "100%|██████████| 47/47 [00:10<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 12\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:16<00:00,  6.54it/s]\n",
      "100%|██████████| 47/47 [00:10<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 13\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:15<00:00,  6.97it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 14\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:15<00:00,  7.08it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loss ===== MultiSimilarity\n",
      "Mean Recall (Class 0): 0.7613636363636365\n",
      "Mean Recall (Class 1): 0.6239907727797002\n",
      "Std Recall (Class 0): 1.1102230246251565e-16\n",
      "Std Recall (Class 1): 0.0\n"
     ]
    }
   ],
   "source": [
    "recall_class_0_list = []\n",
    "recall_class_1_list = []\n",
    "\n",
    "for iteration in range(15):\n",
    "    print(f'-------> RUN {iteration}')\n",
    "    if iteration == 14:\n",
    "        test_labels_real, y_pred = train_and_evaluate(train_dataset, test_dataset, model, True)\n",
    "    else:\n",
    "        test_labels_real, y_pred = train_and_evaluate(train_dataset, test_dataset, model)\n",
    "\n",
    "    report = classification_report(test_labels_real, y_pred, output_dict=True)\n",
    "    recall_class_0_list.append(report['0']['recall'])\n",
    "    recall_class_1_list.append(report['1']['recall'])\n",
    "\n",
    "mean_recall_class_0 = np.mean(recall_class_0_list)\n",
    "mean_recall_class_1 = np.mean(recall_class_1_list)\n",
    "std_recall_class_0 = np.std(recall_class_0_list)\n",
    "std_recall_class_1 = np.std(recall_class_1_list)\n",
    "\n",
    "print(f'\\n Loss ===== {loss_select}')\n",
    "print(f\"Mean Recall (Class 0): {mean_recall_class_0}\")\n",
    "print(f\"Mean Recall (Class 1): {mean_recall_class_1}\")\n",
    "print(f\"Std Recall (Class 0): {std_recall_class_0}\")\n",
    "print(f\"Std Recall (Class 1): {std_recall_class_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving feature extractor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = MODEL_OUT_DIR.joinpath(f'model_{loss_select}_{EXP_NAME}_{timestamp}.pth')\n",
    "torch.save(model.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model = Net(EMBEDDING_SIZE).to(device)\n",
    "triplet_model.load_state_dict(torch.load('./models/v1-dml_2023-11-06\\model_Triplet_v1-dml_2023-11-06.pth'))\n",
    "\n",
    "triplet_model.eval()\n",
    "\n",
    "triplet_clf = load('./models/v1-dml_2023-11-06\\clf_Triplet_v1-dml_2023-11-06.joblib')\n",
    "triplet_scaler = load('./models/v1-dml_2023-11-06\\scaler_Triplet_v1-dml_2023-11-06.joblib')\n",
    "triplet_pca = load('./models/v1-dml_2023-11-06\\pca_Triplet_v1-dml_2023-11-06.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "npairs_model = Net(EMBEDDING_SIZE).to(device)\n",
    "npairs_model.load_state_dict(torch.load('./models/v1-dml_2023-11-06\\model_NPairs_v1-dml_2023-11-06.pth'))\n",
    "\n",
    "npairs_model.eval()\n",
    "\n",
    "npairs_clf = load('./models/v1-dml_2023-11-06\\clf_NPairs_v1-dml_2023-11-06.joblib')\n",
    "npairs_scaler = load('./models/v1-dml_2023-11-06\\scaler_NPairs_v1-dml_2023-11-06.joblib')\n",
    "npairs_pca = load('./models/v1-dml_2023-11-06\\pca_NPairs_v1-dml_2023-11-06.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosface_model = Net(EMBEDDING_SIZE).to(device)\n",
    "cosface_model.load_state_dict(torch.load('./models/v1-dml_2023-11-06\\model_CosFace_v1-dml_2023-11-06.pth'))\n",
    "\n",
    "cosface_model.eval()\n",
    "\n",
    "cosface_clf = load('./models/v1-dml_2023-11-06\\clf_CosFace_v1-dml_2023-11-06.joblib')\n",
    "cosface_scaler = load('./models/v1-dml_2023-11-06\\scaler_CosFace_v1-dml_2023-11-06.joblib')\n",
    "cosface_pca = load('./models/v1-dml_2023-11-06\\pca_CosFace_v1-dml_2023-11-06.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "multisim_model = Net(EMBEDDING_SIZE).to(device)\n",
    "multisim_model.load_state_dict(torch.load('./models/v1-dml_2023-11-06\\model_MultiSimilarity_v1-dml_2023-11-06.pth'))\n",
    "\n",
    "multisim_model.eval()\n",
    "\n",
    "multisim_clf = load('./models/v1-dml_2023-11-06\\clf_MultiSimilarity_v1-dml_2023-11-06.joblib')\n",
    "multisim_scaler = load('./models/v1-dml_2023-11-06\\scaler_MultiSimilarity_v1-dml_2023-11-06.joblib')\n",
    "multisim_pca = load('./models/v1-dml_2023-11-06\\pca_MultiSimilarity_v1-dml_2023-11-06.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label format = {'leish': 0, 'no-leish': 1}\n",
      "train test split proportion = train[7357], test[3154]\n",
      "leish in training set = 5107\n",
      "leish in testing set = 2234\n"
     ]
    }
   ],
   "source": [
    "# data_path = Path('./data-9500train/all_patches/')\n",
    "# x_train, x_test, x_train_loader, x_test_loader, y_true_train, y_true_test = read_data(data_path)\n",
    "# train_dataset, test_dataset, train_loader, test_loader, train_true_labels, test_true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet + CosFace with Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [triplet_clf, cosface_clf]#, npairs_clf, multisim_clf]\n",
    "scalers = [triplet_scaler, cosface_scaler]#, npairs_scaler, multisim_scaler]\n",
    "pcas = [triplet_pca, cosface_pca]#, npairs_pca, multisim_pca]\n",
    "models = [triplet_model, cosface_model]#, npairs_model, multisim_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x_test, models, classifiers, scalers, pcas):\n",
    "    '''\n",
    "    Função para pré-processar e obter previsões de cada classificador\n",
    "    com base nas embeddings extraídas de cada modelo correspondente.\n",
    "    '''\n",
    "    predictions = []\n",
    "    for model, clf, scaler, pca in zip(models, classifiers, scalers, pcas):\n",
    "        test_embed, _ = get_all_embeddings(x_test, model)\n",
    "        test_embed_scaled = scaler.transform(test_embed.cpu().numpy())\n",
    "        test_embed_pca = pca.transform(test_embed_scaled)\n",
    "\n",
    "        preds = clf.predict(test_embed_pca)\n",
    "        predictions.append(preds)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def combine_predictions(predictions):\n",
    "    '''\n",
    "    Função para combinar previsões usando votação majoritária\n",
    "    Axis=0 (col) para votação por amostra\n",
    "    '''\n",
    "    return mode(predictions, axis=0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:10<00:00,  4.28it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Triplet and Cosface models\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.64      0.91      0.75       635\n",
      "    No Leish       0.90      0.62      0.73       848\n",
      "\n",
      "    accuracy                           0.74      1483\n",
      "   macro avg       0.77      0.76      0.74      1483\n",
      "weighted avg       0.79      0.74      0.74      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "individual_preds = get_predictions(test_dataset, classifiers, scalers, pcas)\n",
    "ensemble_prediction = combine_predictions(individual_preds)\n",
    "print('---- Ensemble result for Triplet and Cosface models')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet + Cosface + NPairs with Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.44it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.57it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Triplet, Cosface and NPairs models\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.65      0.78      0.71       635\n",
      "    No Leish       0.81      0.68      0.74       848\n",
      "\n",
      "    accuracy                           0.72      1483\n",
      "   macro avg       0.73      0.73      0.72      1483\n",
      "weighted avg       0.74      0.72      0.72      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [triplet_clf, cosface_clf, npairs_clf]#, multisim_clf]\n",
    "scalers = [triplet_scaler, cosface_scaler, npairs_scaler]#, multisim_scaler]\n",
    "pcas = [triplet_pca, cosface_pca, npairs_pca]#, multisim_pca]\n",
    "models = [triplet_model, cosface_model, npairs_model]#, multisim_model]\n",
    "\n",
    "individual_preds = get_predictions(test_dataset, classifiers, scalers, pcas)\n",
    "ensemble_prediction = combine_predictions(individual_preds)\n",
    "print('---- Ensemble result for Triplet, Cosface and NPairs models')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet + Cosface + MultiSimilarity with Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.39it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.58it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Triplet, Cosface and MultiSimilarity models\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.65      0.80      0.72       635\n",
      "    No Leish       0.82      0.68      0.74       848\n",
      "\n",
      "    accuracy                           0.73      1483\n",
      "   macro avg       0.73      0.74      0.73      1483\n",
      "weighted avg       0.74      0.73      0.73      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [triplet_clf, cosface_clf, multisim_clf]#, npairs_clf]\n",
    "scalers = [triplet_scaler, cosface_scaler, multisim_scaler]#, npairs_scaler]\n",
    "pcas = [triplet_pca, cosface_pca, multisim_pca]#, npairs_pca]\n",
    "models = [triplet_model, cosface_model, multisim_model]#, npairs_model]\n",
    "\n",
    "individual_preds = get_predictions(test_dataset, classifiers, scalers, pcas)\n",
    "ensemble_prediction = combine_predictions(individual_preds)\n",
    "print('---- Ensemble result for Triplet, Cosface and MultiSimilarity models')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models with Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.24it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.48it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.08it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Triplet, Cosface, MultiSimilarity and NPairs models\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.64      0.86      0.73       635\n",
      "    No Leish       0.86      0.64      0.73       848\n",
      "\n",
      "    accuracy                           0.73      1483\n",
      "   macro avg       0.75      0.75      0.73      1483\n",
      "weighted avg       0.77      0.73      0.73      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [triplet_clf, cosface_clf, multisim_clf, npairs_clf]\n",
    "scalers = [triplet_scaler, cosface_scaler, multisim_scaler, npairs_scaler]\n",
    "pcas = [triplet_pca, cosface_pca, multisim_pca, npairs_pca]\n",
    "models = [triplet_model, cosface_model, multisim_model, npairs_model]\n",
    "\n",
    "individual_preds = get_predictions(test_dataset, classifiers, scalers, pcas)\n",
    "ensemble_prediction = combine_predictions(individual_preds)\n",
    "print('---- Ensemble result for Triplet, Cosface, MultiSimilarity and NPairs models')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosface + Triplet with Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_voting(predictions, weights):\n",
    "    \"\"\"\n",
    "    Função para realizar votação ponderada.\n",
    "    predictions: Lista de listas com previsões de cada modelo.\n",
    "    weights: Lista de pesos para cada modelo.\n",
    "    \"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    weighted_predictions = np.zeros(predictions[0].shape)\n",
    "    for preds, weight in zip(predictions, weights):\n",
    "        weighted_predictions += preds * weight\n",
    "    # se a soma ponderada for maior ou igual a 0.5, a classe 1 vence, caso contrário, classe 0\n",
    "    final_preds = np.where(weighted_predictions >= 0.5, 1, 0)\n",
    "\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:10<00:00,  4.50it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Cosface and Triplet\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.69      0.80      0.74       635\n",
      "    No Leish       0.83      0.73      0.77       848\n",
      "\n",
      "    accuracy                           0.76      1483\n",
      "   macro avg       0.76      0.76      0.76      1483\n",
      "weighted avg       0.77      0.76      0.76      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [cosface_clf, triplet_clf]\n",
    "scalers = [cosface_scaler, triplet_scaler]\n",
    "pcas = [cosface_pca, triplet_pca]\n",
    "models = [cosface_model, triplet_model]\n",
    "weights = [0.4, 0.6]\n",
    "\n",
    "predictions = get_predictions(test_dataset, classifiers, scalers, pcas)\n",
    "ensemble_prediction = weighted_voting(predictions, weights)\n",
    "print('---- Ensemble result for Cosface and Triplet')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPairs + CosFace with Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:10<00:00,  4.59it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for NPairs and Cosface\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.63      0.72      0.67       635\n",
      "    No Leish       0.77      0.68      0.72       848\n",
      "\n",
      "    accuracy                           0.70      1483\n",
      "   macro avg       0.70      0.70      0.69      1483\n",
      "weighted avg       0.71      0.70      0.70      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [npairs_clf, cosface_clf]\n",
    "scalers = [npairs_scaler, cosface_scaler]\n",
    "pcas = [npairs_pca, cosface_pca]\n",
    "models = [npairs_model, cosface_model]\n",
    "weights = [0.4, 0.6]\n",
    "\n",
    "predictions = get_predictions(test_dataset, classifiers, scalers, pcas)\n",
    "ensemble_prediction = weighted_voting(predictions, weights)\n",
    "print('---- Ensemble result for NPairs and Cosface')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosface + Triplet + NPairs with Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:09<00:00,  4.87it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.14it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for NPairs, Cosface, Triplet models\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.63      0.72      0.67       635\n",
      "    No Leish       0.77      0.68      0.72       848\n",
      "\n",
      "    accuracy                           0.70      1483\n",
      "   macro avg       0.70      0.70      0.69      1483\n",
      "weighted avg       0.71      0.70      0.70      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [npairs_clf, cosface_clf, triplet_clf]\n",
    "scalers = [npairs_scaler, cosface_scaler, triplet_scaler]\n",
    "pcas = [npairs_pca, cosface_pca, triplet_pca]\n",
    "models = [npairs_model, cosface_model, triplet_model]\n",
    "weights = [0.2, 0.6, 0.2]\n",
    "\n",
    "predictions = get_predictions(test_dataset, classifiers, scalers, pcas)\n",
    "ensemble_prediction = weighted_voting(predictions, weights)\n",
    "print('---- Ensemble result for NPairs, Cosface, Triplet models')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multisim + Cosface + Triplet with Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:10<00:00,  4.55it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.09it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for MultiSim, Cosface, Triplet models\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.69      0.80      0.74       635\n",
      "    No Leish       0.83      0.73      0.77       848\n",
      "\n",
      "    accuracy                           0.76      1483\n",
      "   macro avg       0.76      0.76      0.76      1483\n",
      "weighted avg       0.77      0.76      0.76      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [multisim_clf, cosface_clf, triplet_clf]\n",
    "scalers = [multisim_scaler, cosface_scaler, triplet_scaler]\n",
    "pcas = [multisim_pca, cosface_pca, triplet_pca]\n",
    "models = [multisim_model, cosface_model, triplet_model]\n",
    "weights = [0.2, 0.2, 0.6]\n",
    "\n",
    "predictions = get_predictions(test_dataset, classifiers, scalers, pcas)\n",
    "ensemble_prediction = weighted_voting(predictions, weights)\n",
    "print('---- Ensemble result for MultiSim, Cosface, Triplet models')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosface + Triplet == Cosface + Triplet + Multisim<br>\n",
    "NPairs > MultiSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [multisim_clf, cosface_clf, triplet_clf]\n",
    "scalers = [multisim_scaler, cosface_scaler, triplet_scaler]\n",
    "pcas = [multisim_pca, cosface_pca, triplet_pca]\n",
    "models = [multisim_model, cosface_model, triplet_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def stacking_ensemble(models, classifiers, scalers, pcas, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Treinar um meta-classificador para aprender a melhor maneira de combinar as previsões dos classificadores base.\n",
    "\n",
    "    :param models: Lista de modelos treinados.\n",
    "    :param classifiers: Lista de classificadores correspondentes aos modelos.\n",
    "    :param scalers: Lista de scalers correspondentes aos modelos.\n",
    "    :param pcas: Lista de objetos PCA correspondentes aos modelos.\n",
    "    :param x_train: Dados de treinamento.\n",
    "    :param y_train: Etiquetas verdadeiras de treinamento.\n",
    "    :return: Um modelo meta-classificador treinado.\n",
    "    \"\"\"\n",
    "    base_predictions = get_predictions(x_train, models, classifiers, scalers, pcas)\n",
    "    stacked_features = np.column_stack(base_predictions)\n",
    "\n",
    "    X_meta_train, X_meta_valid, y_meta_train, y_meta_valid = train_test_split(\n",
    "        stacked_features, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    meta_classifier = LogisticRegression()\n",
    "    meta_classifier.fit(X_meta_train, y_meta_train)\n",
    "\n",
    "    # meta_score = meta_classifier.score(X_meta_valid, y_meta_valid)\n",
    "    # print(f\"Meta-classificador score: {meta_score}\")\n",
    "\n",
    "    return meta_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.40it/s]\n",
      "100%|██████████| 109/109 [00:07<00:00, 14.00it/s]\n",
      "100%|██████████| 109/109 [00:07<00:00, 14.00it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.07it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  6.99it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Multsim, Cosface and Triplet\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.69      0.75      0.72       655\n",
      "    No-Leish       0.79      0.74      0.76       828\n",
      "\n",
      "    accuracy                           0.74      1483\n",
      "   macro avg       0.74      0.74      0.74      1483\n",
      "weighted avg       0.75      0.74      0.74      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_clf = stacking_ensemble(models, classifiers, scalers, pcas, train_dataset, train_true_labels)\n",
    "\n",
    "test_predictions = get_predictions(test_dataset, models, classifiers, scalers, pcas)\n",
    "stacked_test_features = np.column_stack(test_predictions)\n",
    "final_predictions = meta_clf.predict(stacked_test_features)\n",
    "print('---- Ensemble result for Multsim, Cosface and Triplet')\n",
    "print(classification_report(test_true_labels, final_predictions, target_names=['Leish', 'No-Leish']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.57it/s]\n",
      "100%|██████████| 109/109 [00:07<00:00, 14.97it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.16it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Cosface and Triplet\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.69      0.82      0.75       655\n",
      "    No-Leish       0.83      0.70      0.76       828\n",
      "\n",
      "    accuracy                           0.76      1483\n",
      "   macro avg       0.76      0.76      0.76      1483\n",
      "weighted avg       0.77      0.76      0.76      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [cosface_clf, triplet_clf]\n",
    "scalers = [cosface_scaler, triplet_scaler]\n",
    "pcas = [cosface_pca, triplet_pca]\n",
    "models = [cosface_model, triplet_model]\n",
    "\n",
    "meta_clf = stacking_ensemble(models, classifiers, scalers, pcas, train_dataset, train_true_labels)\n",
    "\n",
    "test_predictions = get_predictions(test_dataset, models, classifiers, scalers, pcas)\n",
    "stacked_test_features = np.column_stack(test_predictions)\n",
    "final_predictions = meta_clf.predict(stacked_test_features)\n",
    "print('---- Ensemble result for Cosface and Triplet')\n",
    "print(classification_report(test_true_labels, final_predictions, target_names=['Leish', 'No-Leish']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.21it/s]\n",
      "100%|██████████| 109/109 [00:07<00:00, 14.73it/s]\n",
      "100%|██████████| 109/109 [00:07<00:00, 14.44it/s]\n",
      "100%|██████████| 109/109 [00:07<00:00, 14.91it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.20it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.06it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  6.91it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for all models\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.72      0.75      0.73       655\n",
      "    No-Leish       0.79      0.77      0.78       828\n",
      "\n",
      "    accuracy                           0.76      1483\n",
      "   macro avg       0.76      0.76      0.76      1483\n",
      "weighted avg       0.76      0.76      0.76      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [triplet_clf, cosface_clf, npairs_clf, multisim_clf]\n",
    "scalers = [triplet_scaler, cosface_scaler, npairs_scaler, multisim_scaler]\n",
    "pcas = [triplet_pca, cosface_pca, npairs_pca, multisim_pca]\n",
    "models = [triplet_model, cosface_model, npairs_model, multisim_model]\n",
    "\n",
    "meta_clf = stacking_ensemble(models, classifiers, scalers, pcas, train_dataset, train_true_labels)\n",
    "\n",
    "test_predictions = get_predictions(test_dataset, models, classifiers, scalers, pcas)\n",
    "stacked_test_features = np.column_stack(test_predictions)\n",
    "final_predictions = meta_clf.predict(stacked_test_features)\n",
    "print('---- Ensemble result for all models')\n",
    "print(classification_report(test_true_labels, final_predictions, target_names=['Leish', 'No-Leish']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(meta_clf, MODEL_OUT_DIR.joinpath(f'metaclf_AllModels_{EXP_NAME}_{timestamp}.joblib'))\n",
    "meta_clf_logreg = load(MODEL_OUT_DIR.joinpath(f'metaclf_AllModels_{EXP_NAME}_{timestamp}.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET 2 - Getting mean std of models, saving and making ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label format = {'leish': 0, 'no-leish': 1}\n",
      "train test split proportion = train[7357], test[3154]\n",
      "leish in training set = 5156\n",
      "leish in testing set = 2185\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('./data-9500train/all_patches/')\n",
    "x_train, x_test, x_train_loader, x_test_loader, y_true_train, y_true_test = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_func(loss_select):\n",
    "    loss_func = None\n",
    "    if loss_select == 'Triplet':\n",
    "        distance = distances.CosineSimilarity()\n",
    "        reducer = reducers.ThresholdReducer(low=0)\n",
    "        loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "\n",
    "    if loss_select == 'NPairs':\n",
    "        loss_func = losses.NPairsLoss()\n",
    "\n",
    "    if loss_select == 'CosFace':\n",
    "        loss_func = losses.CircleLoss()\n",
    "\n",
    "    if loss_select == 'MultiSimilarity':\n",
    "        loss_func = losses.MultiSimilarityLoss(alpha = 2, beta = 50, base=0.5)\n",
    "\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_recall_stats(train_dataset, test_dataset, model, loss_select, C, gamma):\n",
    "    recall_class_0_list = []\n",
    "    recall_class_1_list = []\n",
    "\n",
    "    for iteration in range(15):\n",
    "        print(f'-------> RUN {iteration}')\n",
    "        if iteration == 14:\n",
    "            test_labels_real, y_pred = train_and_evaluate(train_dataset, test_dataset, model, C, gamma, True)\n",
    "        else:\n",
    "            test_labels_real, y_pred = train_and_evaluate(train_dataset, test_dataset, model, C, gamma)\n",
    "\n",
    "        report = classification_report(test_labels_real, y_pred, output_dict=True)\n",
    "        recall_class_0_list.append(report['0']['recall'])\n",
    "        recall_class_1_list.append(report['1']['recall'])\n",
    "\n",
    "    mean_recall_class_0 = np.mean(recall_class_0_list)\n",
    "    mean_recall_class_1 = np.mean(recall_class_1_list)\n",
    "    std_recall_class_0 = np.std(recall_class_0_list)\n",
    "    std_recall_class_1 = np.std(recall_class_1_list)\n",
    "\n",
    "    print(f'\\n Loss ===== {loss_select}')\n",
    "    print(f\"Mean Recall (Class 0): {mean_recall_class_0}\")\n",
    "    print(f\"Mean Recall (Class 1): {mean_recall_class_1}\")\n",
    "    print(f\"Std Recall (Class 0): {std_recall_class_0}\")\n",
    "    print(f\"Std Recall (Class 1): {std_recall_class_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(loss_select):\n",
    "    model_filename = MODEL_OUT_DIR.joinpath(f'model_{loss_select}_{EXP_NAME}_{timestamp}.pth')\n",
    "    torch.save(model.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 0.2214372605085373\n",
      "Epoch 2 Iteration 0: Loss = 0.20653247833251953\n",
      "Epoch 3 Iteration 0: Loss = 0.21268914639949799\n",
      "Epoch 4 Iteration 0: Loss = 0.21361389756202698\n",
      "Epoch 5 Iteration 0: Loss = 0.18814897537231445\n",
      "Epoch 6 Iteration 0: Loss = 0.22645796835422516\n",
      "Epoch 7 Iteration 0: Loss = 0.18501169979572296\n",
      "Epoch 8 Iteration 0: Loss = 0.18607017397880554\n",
      "Epoch 9 Iteration 0: Loss = 0.20863862335681915\n",
      "Epoch 10 Iteration 0: Loss = 0.3030323088169098\n"
     ]
    }
   ],
   "source": [
    "loss_select = 'Triplet'\n",
    "loss_func = get_loss_func(loss_select)\n",
    "\n",
    "# train_loader\n",
    "# test_loader\n",
    "\n",
    "model = Net(EMBEDDING_SIZE).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "  lss = train(model, loss_func, device, x_train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:08<00:00, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:06<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KNN\n",
      "dimensoes pca: 7\n",
      "(3459, 7)\n",
      "(1483, 7)\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.841 total time=   0.2s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.852 total time=   0.2s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.873 total time=   0.2s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.843 total time=   0.2s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.867 total time=   0.1s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.885 total time=   0.1s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.877 total time=   0.1s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.906 total time=   0.1s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.885 total time=   0.1s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.902 total time=   0.1s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.906 total time=   0.1s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.903 total time=   0.1s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.922 total time=   0.1s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.896 total time=   0.1s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.894 total time=   0.0s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.916 total time=   0.0s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.925 total time=   0.0s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.857 total time=   0.2s\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.841 total time=   0.2s\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.852 total time=   0.3s\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.873 total time=   0.2s\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.843 total time=   0.2s\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.869 total time=   0.1s\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.859 total time=   0.2s\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.864 total time=   0.1s\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.883 total time=   0.2s\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.873 total time=   0.1s\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.885 total time=   0.3s\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.898 total time=   0.3s\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.915 total time=   0.3s\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.912 total time=   0.3s\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.882 total time=   0.2s\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.897 total time=   0.1s\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.901 total time=   0.1s\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.908 total time=   0.1s\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.925 total time=   0.1s\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.897 total time=   0.1s\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.857 total time=   0.3s\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.841 total time=   0.2s\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.852 total time=   0.2s\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.873 total time=   0.2s\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.843 total time=   0.2s\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.849 total time=   0.2s\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.847 total time=   0.2s\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.852 total time=   0.2s\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.883 total time=   0.3s\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.865 total time=   0.1s\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.879 total time=   1.5s\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.883 total time=   1.3s\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.888 total time=   1.3s\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.898 total time=   1.7s\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.878 total time=   1.4s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.897 total time=   0.4s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.899 total time=   0.4s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.909 total time=   0.4s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.927 total time=   0.4s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.892 total time=   0.3s\n",
      "{'C': 10, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "test_embeddings_real, test_labels_real, y_pred = test(train_dataset, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:07<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS ========  Triplet\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       655\n",
      "           1       0.95      0.87      0.90       828\n",
      "\n",
      "    accuracy                           0.90      1483\n",
      "   macro avg       0.90      0.90      0.90      1483\n",
      "weighted avg       0.90      0.90      0.90      1483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_int = test_labels_real.cpu()\n",
    "print('LOSS ======== ', loss_select)\n",
    "print(classification_report(y_test_int, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 0\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:08<00:00, 13.21it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.11it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 1\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.32it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.07it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 2\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.24it/s]\n",
      "100%|██████████| 47/47 [00:07<00:00,  6.67it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 3\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:08<00:00, 13.60it/s]\n",
      "100%|██████████| 47/47 [00:07<00:00,  6.56it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 4\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:08<00:00, 13.48it/s]\n",
      "100%|██████████| 47/47 [00:07<00:00,  6.57it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 5\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:08<00:00, 13.26it/s]\n",
      "100%|██████████| 47/47 [00:07<00:00,  6.34it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 6\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 13.95it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  6.77it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 7\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.59it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.15it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 8\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 15.13it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  6.86it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 9\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.48it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  6.99it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 10\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.78it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.12it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 11\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.79it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.05it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 12\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.86it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  6.99it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 13\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.69it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.15it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 14\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.89it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  6.97it/s]\n",
      "c:\\Users\\ynk9a\\anaconda3\\envs\\tf_GPU\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loss ===== Triplet\n",
      "Mean Recall (Class 0): 0.9374045801526717\n",
      "Mean Recall (Class 1): 0.8659420289855074\n",
      "Std Recall (Class 0): 1.1102230246251565e-16\n",
      "Std Recall (Class 1): 2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "show_recall_stats(train_dataset, test_dataset, model, loss_select, 10, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(loss_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 0.6835356950759888\n",
      "Epoch 2 Iteration 0: Loss = 0.6941480040550232\n",
      "Epoch 3 Iteration 0: Loss = 0.6890720129013062\n",
      "Epoch 4 Iteration 0: Loss = 0.6910037994384766\n",
      "Epoch 5 Iteration 0: Loss = 0.6983157396316528\n",
      "Epoch 6 Iteration 0: Loss = 0.6921732425689697\n",
      "Epoch 7 Iteration 0: Loss = 0.6902471780776978\n",
      "Epoch 8 Iteration 0: Loss = 0.6924971342086792\n",
      "Epoch 9 Iteration 0: Loss = 0.6919410228729248\n",
      "Epoch 10 Iteration 0: Loss = 0.6929746270179749\n"
     ]
    }
   ],
   "source": [
    "loss_select = 'NPairs'\n",
    "loss_func = get_loss_func(loss_select)\n",
    "\n",
    "# train_loader\n",
    "# test_loader\n",
    "\n",
    "model = Net(EMBEDDING_SIZE).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "  lss = train(model, loss_func, device, x_train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:06<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KNN\n",
      "dimensoes pca: 3\n",
      "(3459, 3)\n",
      "(1483, 3)\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.611 total time=   0.5s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.611 total time=   0.4s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.633 total time=   0.4s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.614 total time=   0.5s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.602 total time=   0.4s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.648 total time=   0.3s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.604 total time=   0.2s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.643 total time=   0.3s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.645 total time=   0.2s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.600 total time=   0.3s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.665 total time=   0.2s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.635 total time=   0.3s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.691 total time=   0.3s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.679 total time=   0.3s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.634 total time=   0.3s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.543 total time=   0.3s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.553 total time=   0.3s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.559 total time=   0.3s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.551 total time=   0.3s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.573 total time=   0.3s\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.601 total time=   0.6s\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.602 total time=   0.5s\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.629 total time=   0.5s\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.603 total time=   0.4s\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.607 total time=   0.4s\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.643 total time=   0.7s\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.603 total time=   0.6s\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.673 total time=   0.7s\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.641 total time=   0.6s\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.599 total time=   0.7s\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.675 total time=   0.4s\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.647 total time=   0.4s\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.701 total time=   0.4s\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.679 total time=   0.4s\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.630 total time=   0.4s\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.544 total time=   0.3s\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.562 total time=   0.3s\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.605 total time=   0.3s\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.566 total time=   0.3s\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.576 total time=   0.4s\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.592 total time=   0.8s\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.603 total time=   0.9s\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.617 total time=   0.7s\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.595 total time=   0.4s\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.601 total time=   0.5s\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.619 total time=   4.5s\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.587 total time=   3.9s\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.673 total time=   4.7s\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.626 total time=   4.0s\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.599 total time=   4.6s\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.676 total time=   1.9s\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.630 total time=   1.7s\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.686 total time=   1.9s\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.672 total time=   1.9s\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.625 total time=   2.0s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.589 total time=   0.8s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.578 total time=   0.8s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.627 total time=   0.8s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.595 total time=   0.7s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.581 total time=   0.9s\n",
      "{'C': 100, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "test_embeddings_real, test_labels_real, y_pred = test(train_dataset, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:07<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS ========  NPairs\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       655\n",
      "           1       0.76      0.63      0.69       828\n",
      "\n",
      "    accuracy                           0.68      1483\n",
      "   macro avg       0.69      0.69      0.68      1483\n",
      "weighted avg       0.70      0.68      0.68      1483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_int = test_labels_real.cpu()\n",
    "print('LOSS ======== ', loss_select)\n",
    "print(classification_report(y_test_int, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 0\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.54it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 1\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.95it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 2\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.75it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 3\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.73it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 4\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.59it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 5\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.57it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 6\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.44it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 7\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.64it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 8\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.66it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 9\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.45it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 10\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 15.12it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 11\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.71it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 12\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.43it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 13\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.39it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 14\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 14.80it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loss ===== NPairs\n",
      "Mean Recall (Class 0): 0.7526717557251907\n",
      "Mean Recall (Class 1): 0.6280193236714975\n",
      "Std Recall (Class 0): 1.1102230246251565e-16\n",
      "Std Recall (Class 1): 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "show_recall_stats(train_dataset, test_dataset, model, loss_select, 100, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(loss_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CosFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 70.23455047607422\n",
      "Epoch 2 Iteration 0: Loss = 58.894168853759766\n",
      "Epoch 3 Iteration 0: Loss = 57.77741241455078\n",
      "Epoch 4 Iteration 0: Loss = 56.41551208496094\n",
      "Epoch 5 Iteration 0: Loss = 56.42686462402344\n",
      "Epoch 6 Iteration 0: Loss = 55.74510955810547\n",
      "Epoch 7 Iteration 0: Loss = 55.024375915527344\n",
      "Epoch 8 Iteration 0: Loss = 54.48646545410156\n",
      "Epoch 9 Iteration 0: Loss = 53.84113311767578\n",
      "Epoch 10 Iteration 0: Loss = 52.557159423828125\n"
     ]
    }
   ],
   "source": [
    "loss_select = 'CosFace'\n",
    "loss_func = get_loss_func(loss_select)\n",
    "\n",
    "# train_loader\n",
    "# test_loader\n",
    "\n",
    "model = Net(EMBEDDING_SIZE).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "  lss = train(model, loss_func, device, x_train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KNN\n",
      "dimensoes pca: 8\n",
      "(3459, 8)\n",
      "(1483, 8)\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.557 total time=   0.3s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.528 total time=   0.3s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.535 total time=   0.3s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.545 total time=   0.3s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.539 total time=   0.3s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.759 total time=   0.2s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.776 total time=   0.2s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.784 total time=   0.2s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.785 total time=   0.2s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.772 total time=   0.2s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.825 total time=   0.1s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.815 total time=   0.1s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.815 total time=   0.1s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.818 total time=   0.1s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.776 total time=   0.1s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.777 total time=   0.1s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.790 total time=   0.1s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.777 total time=   0.1s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.780 total time=   0.1s\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.557 total time=   0.2s\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.528 total time=   0.3s\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.535 total time=   0.3s\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.545 total time=   0.3s\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.539 total time=   0.3s\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.759 total time=   0.3s\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.785 total time=   0.2s\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.785 total time=   0.2s\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.772 total time=   0.2s\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.818 total time=   0.3s\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.813 total time=   0.3s\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.807 total time=   0.3s\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.800 total time=   0.3s\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.818 total time=   0.3s\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.840 total time=   0.2s\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.810 total time=   0.2s\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.827 total time=   0.2s\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.810 total time=   0.2s\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.791 total time=   0.2s\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.557 total time=   0.3s\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.528 total time=   0.3s\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.535 total time=   0.3s\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.545 total time=   0.4s\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.539 total time=   0.3s\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.759 total time=   0.3s\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.785 total time=   0.3s\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.785 total time=   0.3s\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.772 total time=   0.3s\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.794 total time=   0.8s\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.775 total time=   0.7s\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.782 total time=   0.8s\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.768 total time=   0.7s\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.792 total time=   0.8s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.839 total time=   0.6s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.824 total time=   0.6s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.828 total time=   0.7s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.829 total time=   0.6s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.820 total time=   0.7s\n",
      "{'C': 1000, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "test_embeddings_real, test_labels_real, y_pred = test(train_dataset, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS ========  CosFace\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       655\n",
      "           1       0.88      0.88      0.88       828\n",
      "\n",
      "    accuracy                           0.86      1483\n",
      "   macro avg       0.86      0.86      0.86      1483\n",
      "weighted avg       0.86      0.86      0.86      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_int = test_labels_real.cpu()\n",
    "print('LOSS ======== ', loss_select)\n",
    "print(classification_report(y_test_int, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 0\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.13it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 1\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 18.05it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 2\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.67it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 3\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.98it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 4\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.67it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 5\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.91it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 6\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.50it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 7\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.40it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 8\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.82it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 9\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.77it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 10\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.45it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 11\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.86it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 12\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.47it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 13\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.40it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 14\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.31it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loss ===== CosFace\n",
      "Mean Recall (Class 0): 0.8427480916030532\n",
      "Mean Recall (Class 1): 0.8768115942028986\n",
      "Std Recall (Class 0): 2.220446049250313e-16\n",
      "Std Recall (Class 1): 0.0\n"
     ]
    }
   ],
   "source": [
    "show_recall_stats(train_dataset, test_dataset, model, loss_select, 1000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(loss_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iteration 0: Loss = 2.3075778484344482\n",
      "Epoch 2 Iteration 0: Loss = 2.232682466506958\n",
      "Epoch 3 Iteration 0: Loss = 2.2047579288482666\n",
      "Epoch 4 Iteration 0: Loss = 2.2096004486083984\n",
      "Epoch 5 Iteration 0: Loss = 2.2154150009155273\n",
      "Epoch 6 Iteration 0: Loss = 2.2389025688171387\n",
      "Epoch 7 Iteration 0: Loss = 2.1953234672546387\n",
      "Epoch 8 Iteration 0: Loss = 2.1957101821899414\n",
      "Epoch 9 Iteration 0: Loss = 2.2289013862609863\n",
      "Epoch 10 Iteration 0: Loss = 2.2216076850891113\n"
     ]
    }
   ],
   "source": [
    "loss_select = 'MultiSimilarity'\n",
    "loss_func = get_loss_func(loss_select)\n",
    "\n",
    "# train_loader\n",
    "# test_loader\n",
    "\n",
    "model = Net(EMBEDDING_SIZE).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "  lss = train(model, loss_func, device, x_train_loader, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KNN\n",
      "dimensoes pca: 2\n",
      "(3459, 2)\n",
      "(1483, 2)\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.879 total time=   0.1s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.844 total time=   0.1s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.863 total time=   0.1s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.861 total time=   0.1s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.854 total time=   0.1s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.866 total time=   0.1s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.832 total time=   0.0s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.856 total time=   0.1s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.839 total time=   0.0s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.853 total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.845 total time=   0.1s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.791 total time=   0.1s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.834 total time=   0.1s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.800 total time=   0.1s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.829 total time=   0.1s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.680 total time=   0.2s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.673 total time=   0.2s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.688 total time=   0.2s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.694 total time=   0.2s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.695 total time=   0.2s\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.862 total time=   0.2s\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.850 total time=   0.2s\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.870 total time=   0.2s\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.863 total time=   0.2s\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.878 total time=   0.1s\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.842 total time=   0.1s\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.861 total time=   0.1s\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.852 total time=   0.1s\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.864 total time=   0.1s\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.857 total time=   0.1s\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.815 total time=   0.1s\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.844 total time=   0.1s\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.827 total time=   0.1s\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.826 total time=   0.1s\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.767 total time=   0.1s\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.728 total time=   0.1s\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.740 total time=   0.1s\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.771 total time=   0.1s\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.869 total time=   1.0s\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.848 total time=   0.5s\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.868 total time=   0.5s\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.857 total time=   0.8s\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.855 total time=   0.8s\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.882 total time=   0.2s\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.853 total time=   0.2s\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.862 total time=   0.2s\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.862 total time=   0.2s\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.859 total time=   0.2s\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.823 total time=   0.1s\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.842 total time=   0.2s\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.830 total time=   0.2s\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.820 total time=   0.2s\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.775 total time=   0.2s\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.805 total time=   0.2s\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.780 total time=   0.2s\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.807 total time=   0.2s\n",
      "{'C': 1000, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "test_embeddings_real, test_labels_real, y_pred = test(train_dataset, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS ========  MultiSimilarity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       655\n",
      "           1       0.90      0.89      0.89       828\n",
      "\n",
      "    accuracy                           0.88      1483\n",
      "   macro avg       0.88      0.88      0.88      1483\n",
      "weighted avg       0.88      0.88      0.88      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_int = test_labels_real.cpu()\n",
    "print('LOSS ======== ', loss_select)\n",
    "print(classification_report(y_test_int, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 0\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:05<00:00, 18.20it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 1\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.99it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 2\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 18.00it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 3\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.88it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 4\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.83it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 5\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 18.03it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 6\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.77it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 7\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.82it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 8\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.93it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 9\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.74it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 10\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.89it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 11\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.90it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 12\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.79it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 13\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.51it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------> RUN 14\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:06<00:00, 17.85it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loss ===== MultiSimilarity\n",
      "Mean Recall (Class 0): 0.8778625954198472\n",
      "Mean Recall (Class 1): 0.885265700483092\n",
      "Std Recall (Class 0): 1.1102230246251565e-16\n",
      "Std Recall (Class 1): 2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "show_recall_stats(train_dataset, test_dataset, model, loss_select, 1000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(loss_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods (dataset 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model = Net(EMBEDDING_SIZE).to(device)\n",
    "triplet_model.load_state_dict(torch.load('./models/v1-ensble_2023-11-07\\model_Triplet_v1-ensble_2023-11-07.pth'))\n",
    "\n",
    "triplet_model.eval()\n",
    "\n",
    "triplet_clf = load('./models/v1-ensble_2023-11-07\\clf_Triplet_v1-ensble_2023-11-07.joblib')\n",
    "triplet_scaler = load('./models/v1-ensble_2023-11-07\\scaler_Triplet_v1-ensble_2023-11-07.joblib')\n",
    "triplet_pca = load('./models/v1-ensble_2023-11-07\\pca_Triplet_v1-ensble_2023-11-07.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosface_model = Net(EMBEDDING_SIZE).to(device)\n",
    "cosface_model.load_state_dict(torch.load('./models/v1-ensble_2023-11-07\\model_CosFace_v1-ensble_2023-11-07.pth'))\n",
    "\n",
    "cosface_model.eval()\n",
    "\n",
    "cosface_clf = load('./models/v1-ensble_2023-11-07\\clf_CosFace_v1-ensble_2023-11-07.joblib')\n",
    "cosface_scaler = load('./models/v1-ensble_2023-11-07\\scaler_CosFace_v1-ensble_2023-11-07.joblib')\n",
    "cosface_pca = load('./models/v1-ensble_2023-11-07\\pca_CosFace_v1-ensble_2023-11-07.joblib')\n",
    "\n",
    "################################\n",
    "\n",
    "multisim_model = Net(EMBEDDING_SIZE).to(device)\n",
    "multisim_model.load_state_dict(torch.load('./models/v1-ensble_2023-11-07\\model_MultiSimilarity_v1-ensble_2023-11-07.pth'))\n",
    "\n",
    "multisim_model.eval()\n",
    "\n",
    "multisim_clf = load('./models/v1-ensble_2023-11-07\\clf_MultiSimilarity_v1-ensble_2023-11-07.joblib')\n",
    "multisim_scaler = load('./models/v1-ensble_2023-11-07\\scaler_MultiSimilarity_v1-ensble_2023-11-07.joblib')\n",
    "multisim_pca = load('./models/v1-ensble_2023-11-07\\pca_MultiSimilarity_v1-ensble_2023-11-07.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet + MultiSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [triplet_clf, multisim_clf]#, cosface_clf]\n",
    "scalers = [triplet_scaler, multisim_scaler]#,  cosface_scaler]\n",
    "pcas = [triplet_pca, multisim_pca]#, cosface_pca]\n",
    "models = [triplet_model, multisim_model]#, cosface_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.60it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Triplet and MultiSimilarity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.86      0.88      0.87       655\n",
      "    No Leish       0.90      0.89      0.89       828\n",
      "\n",
      "    accuracy                           0.88      1483\n",
      "   macro avg       0.88      0.88      0.88      1483\n",
      "weighted avg       0.88      0.88      0.88      1483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weights = [0.3,0.7]\n",
    "predictions = get_predictions(test_dataset, models, classifiers, scalers, pcas)\n",
    "ensemble_prediction = weighted_voting(predictions, weights)\n",
    "print('---- Ensemble result for Triplet and MultiSimilarity')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet + Cosface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [triplet_clf, cosface_clf]#, ]multisim_clf\n",
    "scalers = [triplet_scaler, cosface_scaler]#,  multisim_scaler]\n",
    "pcas = [triplet_pca, cosface_pca]#, ]multisim_pca\n",
    "models = [triplet_model, cosface_model]#, ]multisim_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.55it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Triplet and Cosface\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.84      0.84      0.84       655\n",
      "    No Leish       0.88      0.88      0.88       828\n",
      "\n",
      "    accuracy                           0.86      1483\n",
      "   macro avg       0.86      0.86      0.86      1483\n",
      "weighted avg       0.86      0.86      0.86      1483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weights = [0.4,0.6]\n",
    "predictions = get_predictions(test_dataset, models, classifiers, scalers, pcas)\n",
    "ensemble_prediction = weighted_voting(predictions, weights)\n",
    "print('---- Ensemble result for Triplet and Cosface')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet + Cosface + Multisim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [triplet_clf, cosface_clf, multisim_clf]\n",
    "scalers = [triplet_scaler, cosface_scaler,  multisim_scaler]\n",
    "pcas = [triplet_pca, cosface_pca, multisim_pca]\n",
    "models = [triplet_model, cosface_model, multisim_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.47it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.60it/s]\n",
      "100%|██████████| 47/47 [00:05<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Triplet, Cosface, Multisimilarity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.90      0.94      0.92       655\n",
      "    No Leish       0.95      0.92      0.93       828\n",
      "\n",
      "    accuracy                           0.93      1483\n",
      "   macro avg       0.92      0.93      0.92      1483\n",
      "weighted avg       0.93      0.93      0.93      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "individual_preds = get_predictions(test_dataset, models, classifiers, scalers, pcas)\n",
    "ensemble_prediction = combine_predictions(individual_preds)\n",
    "print('---- Ensemble result for Triplet, Cosface, Multisimilarity')\n",
    "print(classification_report(test_true_labels, ensemble_prediction, target_names=['Leish', 'No Leish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet + Cosface + Multisim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:07<00:00, 15.33it/s]\n",
      "100%|██████████| 109/109 [00:07<00:00, 15.43it/s]\n",
      "100%|██████████| 109/109 [00:07<00:00, 15.19it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.14it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.25it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ensemble result for Triplet, Cosface and MultiSim\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Leish       0.91      0.90      0.91       655\n",
      "    No-Leish       0.92      0.93      0.93       828\n",
      "\n",
      "    accuracy                           0.92      1483\n",
      "   macro avg       0.92      0.92      0.92      1483\n",
      "weighted avg       0.92      0.92      0.92      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_clf = stacking_ensemble(models, classifiers, scalers, pcas, train_dataset, train_true_labels)\n",
    "\n",
    "test_predictions = get_predictions(test_dataset, models, classifiers, scalers, pcas)\n",
    "stacked_test_features = np.column_stack(test_predictions)\n",
    "final_predictions = meta_clf.predict(stacked_test_features)\n",
    "print('---- Ensemble result for Triplet, Cosface and MultiSim')\n",
    "print(classification_report(test_true_labels, final_predictions, target_names=['Leish', 'No-Leish']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
